# ğŸ¥ StyleSync AI â€” Video-to-Catalog Product Tagging + Vibe Detection

StyleSync AI is a backend ML pipeline built for the **Flickd AI Hackathon**. It detects fashion items in short-form creator videos, matches them to a product catalog using CLIP embeddings, and classifies the video into 1â€“3 fashion "vibes" from a predefined taxonomy.

---

## ğŸ§  What It Does

- Detects clothing and accessories using **YOLOv8**
- Crops detected objects from frames
- Matches objects to a **Shopify catalog** using **CLIP + FAISS**
- Classifies fashion "vibes" using **NLP** on captions
- Outputs a structured **JSON** per video

---

## ğŸ“ Project Structure

```
stylesync-ai/
â”œâ”€â”€ frames/ # Extracted frames for each video
â”œâ”€â”€ cropped_objects/ # Cropped detected fashion objects per frame
â”œâ”€â”€ models/ # Cached catalog embeddings (catalog_embeddings.npy)
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ product_data.xlsx # Catalog metadata: id, type, tags
â”‚ â”œâ”€â”€ images.csv # Product image URLs (id, image_url)
â”‚ â”œâ”€â”€ vibeslist.json # List of predefined "vibe" labels
â”‚ â””â”€â”€ outputs_final/ # Final prediction JSONs per video
â”œâ”€â”€ outputs/ # Object detection results (YOLO JSON per video)
â”œâ”€â”€ notebooks/
â”‚ â””â”€â”€ main_pipeline.ipynb # End-to-end notebook pipeline
â”œâ”€â”€ requirements.txt # Python dependencies
â””â”€â”€ README.md # You are here
```

## â–¶ï¸ Run the Full Pipeline

Run the following notebooks in order:

### 1. [`extract_frames.ipynb`](notebooks/extract_frames.ipynb)
- Extracts frames from input videos
- Saves frames to: `frames/<video_id>/`

### 2. [`detect_objects.ipynb`](notebooks/detect_objects.ipynb)
- Uses YOLOv8 to detect clothing and accessories in frames
- Outputs detection results (with bounding boxes and class labels) to: `outputs/<video_id>.json`

### 3. [`flickd_product_recommendation_pipeline.ipynb`](notebooks/flickd_product_recommendation_pipeline.ipynb)
This notebook performs the following steps:

- ğŸ–¼ï¸ **Crop detected items** from frames using YOLO results  
- ğŸ”— **Embed each crop** using CLIP (OpenAI or HuggingFace)  
- ğŸ›ï¸ **Match crops to catalog items** using cosine similarity with FAISS  
- ğŸ§  **Predict vibes** using mean embedding vectors and NLP (e.g., DistilBERT)  
- ğŸ“„ **Save final results** as structured JSON in: `data/outputs_final/<video_id>.json`

## ğŸ“¦ Example Output

Each video generates a structured JSON like this:

```json
{
  "video_id": "2025-06-02_11-31-19_UTC",
  "vibes": ["Clean Girl", "Boho", "Cottagecore"],
  "products": [
    {
      "type": "Dress",
      "color": "Colour: White, Fabric: Cotton",
      "image_url": "https://cdn.shopify.com/...",
      "matched_product_id": 1234,
      "match_type": "similar",
      "confidence": 0.84
    }
  ]
}
```

## ğŸ§  How It Works

### ğŸ•µï¸â€â™‚ï¸ Object Detection
YOLOv8 detects fashion items in video frames and outputs:
- Class labels (e.g., dress, bag, top)
- Bounding boxes (x, y, width, height)
- Confidence scores per detection

### ğŸ§¬ Embedding
CLIP (Contrastive Language-Image Pretraining) encodes:
- Each cropped object from the video frame
- Each product image in the catalog  
It generates high-dimensional vector embeddings for visual similarity comparison.

### ğŸ”— Matching
Embeddings from the detected items are:
- Compared with catalog embeddings using **cosine similarity**
- Accelerated using **FAISS** (Facebook AI Similarity Search)
- Labeled as `exact`, `similar`, or `no match` based on a similarity threshold

### ğŸ¯ Vibe Classification
Captions and hashtags (or optional audio transcript) are:
- Analyzed using transformer-based NLP (e.g., DistilBERT)
- Classified into 1â€“3 fashion vibes from the predefined taxonomy:  
  `["Coquette", "Clean Girl", "Cottagecore", "Streetcore", "Y2K", "Boho", "Party Glam"]`

## ğŸ“¹ Loom Demo Video

ğŸ¥ Watch the demo of the complete pipeline in action:

## ğŸ“½ Demo Video

Watch the full demo on Loom:  
ğŸ‘‰ [Click here to watch](https://www.loom.com/share/fea9f75bac024ed4a5fe2bd40860dd47?sid=f0261a7a-5dba-411c-8c6b-89748ab65ba0)

---

## ğŸ› ï¸ Requirements

Make sure you have **Python 3.8+** installed.

### Required Python Packages:

- `torch`
- `torchvision`
- `transformers`
- `pandas`
- `numpy`
- `opencv-python`
- `scikit-learn`
- `tqdm`
- `ultralytics`  _(for YOLOv8)_

### Install All Dependencies

```bash
pip install -r requirements.txt
```
